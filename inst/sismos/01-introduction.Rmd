
# <span style="color:blue">**Contenido de la Data**</span>

```{r include = FALSE}
library(readr) # leer .csv
library(dplyr) # procesamiento de datos
library(skimr) # muestra variables categoricas y numericas
```

A continuación se presenta la base de datos a utilizar en la investigación. 


```{r}
#sismo <- read_csv("C:/Users/victo/Documents/Maestría/1.2. Segundo semestre/Series de tiempo/data_sismo.csv")#Victoria
sismo <- read_csv("../../data_sismo.csv")#wladimir
#sismo <- read_csv("D:/Documentos/GitHub/Series_de_tiempo/data_sismo.csv")#Mario
sismo <- mutate_if(sismo, is.character, tolower) # pasamos a minúsculas
glimpse(sismo)
```

## <span style="color:darkgreen">**Observación de los datos**</span>


### **El Tiempo Universal Coordinado (HORA_UTC):**
Es una escala de tiempo que es mantenida por los laboratorios de tiempo de todo el mundo y es determinada por relojes atómicos de alta precisión. El tiempo UTC es preciso a aproximadamente un nanosegundo (millonésima parte de un segundo) por día.

### **Magnitud Local (Ml):**
Donde A es la máxima amplitud de la traza registrada y Ao la amplitud máxima que sería producida por un sismo patrón, siendo éste aquel que produciría una deflexión de 0.001 mm en un sismógrafo ubicado a 100 km del epicentro.

### **Magnitud de momento (Mw):**
Esta magnitud es la más robusta; a diferencia de ML, mB y MS, la escala Mw no se satura, por lo que hoy en día es la más confiable y la más usada por las agencias dedicadas a la detección de sismos. También es la magnitud más usada por científicos para comparar los tamaños entre sismos.

### **Root Mean Square (RMS):**
Es la medida del error, comparando la diferencia promedio entre el tiempo de arribo teórico y el tiempo de arribo observado en segundos, utilizando las lecturas de los sismogramas.

### **Brecha sísmica (GAP):**

Zona geológica en la que no ha ocurrido un sismo fuerte durante un periodo prolongado de tiempo.


## <span style="color:darkgreen">**Descripción Datos** </span>

```{r}
skim(sismo)
```
La profundidad de sismos en kilómetros muestra una media de 145.0610908, con una desviación estándar de 5.16222274.Por su aprte, las magnitudes Ml y Mw, tienen medias de 1.8909980 y 3.4296736 respectivamente. La magnitud Mw muestra una tasa de completitud más baja, con un 5.97% de datos faltantes.

El número de fases registradas por evento tiene una media de 9.8856949, el RMS (Root Mean Square) y GAP (Brecha) presentan una media de 0.3912964 y 144.3370952 respectivamente.

## <span style="color:darkgreen">**Imputar Datos**</span>

* Existen **31826** datos faltantes **NA** para la variable **Magnitud Mw** por tanto se decide remover de la base de datos 
* Para las demás variables de tipo categórico, fecha, tiempo, y numérico no hay datos faltantes
* Las variables categóricas corresponden a la descripción del departamento de Santander, en su municipio de Los_Santos y para la columna estado se encuentran todos los datos en revisado, por tanto se procede a removerlas de la data original sismo
* Para el ejercicio académico se ha decidido remover las variables de error de latitud, longitud, y profundidad
* También se renombra las variables que contienen comillas en su estructura de columnas

```{r}
sismo_2 <- sismo
# las columnas retiradas fueron 7,8,9,13,14,15,16
sismo_2 <- sismo_2 [, c(1,2,3,4,5,6,10,11,12)] # data con 9 variables
colnames(sismo_2)[3] <-"LATITUD"  # renombrar variable
colnames(sismo_2)[4] <-"LONGITUD"  # renombrar variable
colnames(sismo_2)[5] <-"PROFUNDIDAD"  # renombrar variable
colnames(sismo_2)[6] <-"MAGNITUD_ML"  # renombrar variable
colnames(sismo_2)[7] <-"NUM_FASES"  # renombrar variable
colnames(sismo_2)[8] <-"RMS"  # renombrar variable
colnames(sismo_2)[9] <-"GAP"  # renombrar variable
head(sismo_2)
```

# <span style="color:blue">**Variable Numéricas**</span>

Los siguientes gráficos muestran la distribución de la latitud, longitud, profundidad, magnitud, número de fases,  Root Mean Square ( RMS) y la brecha sismica (GAP) de los sismos en el municipio de Los Santos, Santander. Cada gráfico representa la frecuencia de sismos en el eje Y un dato específico relacionado con cada una de las variables en el eje x.

La profundidad presenta una media de 145 km, con relación a la magnitud es una forma asimetrica a la derecha con una media  de  1.8, el número de fases es una forma asimetrica a la izquierda y tiene una media de 9.8, por su parte el RMS y el GAP presentan una forma multimodal ya que aparecen varios picos y sus medias son de 0.3 y de 144 respectivamente.

```{r include = FALSE}
library(ggpubr) # visualización
library(plotly) # visualización
library(CGPfunctions) # gráfica cuantitativas
library(ggplot2)
```

```{r}
g1 = ggplot(sismo_2, aes(x = LATITUD)) + geom_histogram(fill="royalblue") + theme_gray()
g2 = ggplot(sismo_2, aes(x = LONGITUD)) + geom_histogram(fill="royalblue") + theme_gray()
g3 = ggplot(sismo_2, aes(x = PROFUNDIDAD)) + geom_histogram(fill="royalblue") + theme_gray()
g4 = ggplot(sismo_2, aes(x = MAGNITUD_ML)) + geom_histogram(fill="royalblue") + theme_gray()
g5 = ggplot(sismo_2, aes(x = NUM_FASES)) + geom_histogram(fill="royalblue") + theme_gray()
g6 = ggplot(sismo_2, aes(x = RMS)) + geom_histogram(fill="royalblue") + theme_gray()
g7 = ggplot(sismo_2, aes(x = GAP)) + geom_histogram(fill="royalblue") + theme_gray()


ggarrange(g1, g2, g3, g4, g5, g6, g7, labels = c("A", "B", "C","D", "E", "F","G"), ncol = 2, nrow = 2)
```

# <span style="color:darkgreen">**Variable Serie Tiempo** </span>

```{r setup, include = FALSE}
library(forecast) #predicción
library(tseries)  #análisis de series de tiempo
library(timsac)
library(changepoint) #detectar puntos de cambios
```

**Análisis de la Data**

A continuación se se seleccionan las variables de análisis para el presente ejercicio:

Profundidad: esta variable se selcciono dado que representa la profundidad del foco sísmico y este influye en cómo se siente un terremoto en la superficie, los terremotos superficiales, son aquellos que tienen un foco a menos de 70 km de profundidad, estos generalmente causan mas daño ya que la energía que liberan no se dispera tanto antes de llegar a la superficie. 

Magnitud: la magnitud en Colombia se reorta utilizando la escala de Richter, esta medida permite conocer cuanta es la energía liberada por un sismo.

```{r}
sismo_3 <- sismo_2 # copiamos data2
sismo_3 <- sismo_3 [, c(1,5,6)] # data con 3 variables 1:fecha, 5:profundidad, 6:magnitud
#sismo_3$fecha_hora <- paste(sismo_3$FECHA," ",sismo_3$HORA_UTC)# unir columnas 1 y 2
#sismo_3$fecha_hora <- as.POSIXct(sismo_3$fecha_hora) # convertir a tipo date time
#sismo_3$FECHA_UNIX <- as.POSIXct(sismo_3$FECHA)
sismo_3 <- sismo_3[order(sismo_3$FECHA), ] #ordenamo sismo_3 de menor a mayor
head(sismo_3,2)
```

Se agrupan las fechas para obtener un dato único por día, con relación a la magnitud se decidió calcular el maximo de cada día para conocer el sismo que libera la mayor cantidad de energía y con relación a la profundidad se decidió calcular el minimo con el fin de determianr el sismo que esta mas cerca a la superficie y puede causar mas daño.

```{r}
sismo_4_max <- sismo_3 %>% # Agrupamos por fecha y obtenemos el máximo de la magnitud para cada fecha
  group_by(FECHA) %>% 
  summarise(MAX_MAGNITUD_ML = max(MAGNITUD_ML),
            MIN_PROFUNDIDAD = min(PROFUNDIDAD))
head(sismo_4_max, 2)
```

Dado que no hay información para todos los días del año entre el 28 de febrero de 2011 y el 28 de febrero de 2018 primero se creo un data frame con todas las fechas en ese rango y posteriormente los datos faltantes en las variables MAGNITUD Y PROFUNCIDAD se llenaron de la siguiente forma:

Profundidad: la profundidad se decio llenar con la media que es 145.0610908. Esta decición esta fundamentada en que la revisar la gráfica de series de tiempo, si se llenaran con profundidad 0 generaria mucho ruido y no permitiria visualizar adecuadamente los simso que realmente presentan una profundida baja y cercana a la superficie.

Magnitud: la magnitud se decidio llenar con 0.

```{r}
# Crear un data frame con todas las fechas en el rango deseado
todas_las_fechas <- data.frame(FECHA = seq(as.Date("2011-02-28"), as.Date("2018-02-28"), by = "day"))

sismo_4_max_completo <- todas_las_fechas %>%
  left_join(sismo_4_max, by = "FECHA") %>%
  mutate(MAX_MAGNITUD_ML = ifelse(is.na(MAX_MAGNITUD_ML), 0, MAX_MAGNITUD_ML),
         MIN_PROFUNDIDAD = ifelse(is.na(MIN_PROFUNDIDAD), 145.0610908, MIN_PROFUNDIDAD))

# Filtrar desde el 28 de febrero de 2017 hasta el 28 de febrero de 2018
sismo_4_max_completo_filtrado <- sismo_4_max_completo %>%
  filter(FECHA >= as.Date("2017-02-28") & FECHA <= as.Date("2018-02-28"))

head(sismo_4_max_completo_filtrado, 2)
```

Se revisa que el número de filas concurde para comprobar que se encuentran todos los días entre el 28 de febrero de 2011 y el 28 de febrero de 2018.

```{r}
nrow(todas_las_fechas)
```

```{r}
nrow(sismo_4_max_completo_filtrado)
```

**Serie de tiempo Magnitud**

```{r}
indice.ts <- ts(sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML,start = c(2017,2),end = c(2018,2), frequency = 365)
#head(indice.ts,10) 
head(indice.ts)
```

**Datos de la serie**

```{r}
"Tipo ts"
class(indice.ts)
"Inicio serie"
start(indice.ts)
"fin serie"
end(indice.ts)
```

**Gráfica de la serie**


```{r}
hist(indice.ts,main="",ylab="valor", col='orange', xlab ="MAGNITUD_ML")
title(main="MAGNITUD DEL SISMO EN EL TIEMPO")
```
La distribución de la magnitud de los sismos en el municipio de Los Santos Santander evidencia que la mayoria de los sismos presentados son de magnitud baja y no presnetan un mayor riezgo para la población. Hay presencia de sismos de magnitud fuerte sin embargo hay que revisar la profundidad de estos para determinar si causan daños a la población.


```{r}
plot(indice.ts,main="",ylab="valor", col='orange', xlab ="FECHA")
title(main="MAGNITUD DEL SISMO EN EL TIEMPO")
```

**Serie de tiempo Profundidad**

```{r}
P_indice.ts <- ts(sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD,start = c(2017,2),end = c(2018,2), frequency = 365)
#head(indice.ts,10) 
head(P_indice.ts)
```

**Datos de la serie**

```{r}
"Tipo ts"
class(P_indice.ts)
"Inicio serie"
start(P_indice.ts)
"fin serie"
end(P_indice.ts)
```

**Gráfica de la serie**

```{r}
hist(P_indice.ts,main="",ylab="valor", col='saddlebrown', xlab ="PROFUNDIDA")
title(main="PROFUNDIDAD DEL SISMO (KM) EN EL TIEMPO")
```
La distribución de la profundiad de los sismos en el municipio de Los Santos Santander evidencia que la mayoria de los sismos presentados son de alta profunidad y no presnetan un mayor riezgo para la población. 



```{r}
plot(P_indice.ts,main="",ylab="valor", col='saddlebrown', xlab ="FECHA")
title(main="PROFUNDIDAD DEL SISMO (KM) EN EL TIEMPO")
```


# <span style="color:blue">**Holt-Winter**</span>

A continuación, se aplica la metolodgía Holt-Winter y de suavizamiento a la variable tiempo. Esta técnica de análisis de series temporales se utiliza para predecir datos con componentes de tendencia y estacioanlidad.

## Magnitud

```{r}
library(aTSA)

# Transformar la serie (si es necesario)
adf.test(diff(indice.ts))
```

## Profundidad

```{r}
library(aTSA)

# Transformar la serie (si es necesario)
adf.test(diff(P_indice.ts))
```


Teniendo en cuenta los resultados del test de Dickey-Fuller aumentado (ADF), se evidencio que todos los valores del estadístico ADF son negativos y los valores p son 0.01 para todos tipos de prueba: 

* Tipo 1: sin deriva y sin tendencia
* Tipo 2: con deriva y sin tendencia
* Tipo 3: con deriva y tendencia

Con base en lo anterior hay suficiente evidencia para rechazar la hipótesis nula de una raíz unitaria, concluyendo que la serie temporal es estacionaria. 

# <span style="color:blue">**ARIMA**</span>

A continuación, se aplica la metodología Box-Jenkins también conocida como ARIMA, este es un enfoque sistemático para construir modelos de series temporales que pueden predecir valores futuros basados en valores pasados y se utiliza especialmente cuando los datos no tienen una tendencia clara o una estacionalidad simple como es el caso de nuestros datos. 

Teniendo en cuenta lo mencionado anteriormente y dado que el modelo ARIMA es particularmente adecuado para series temporales estacionarias, se justifica su uso en lugar del modelo Holt-Winters. 

Este último es más adecuado para datos con componentes de tendencia y estacionalidad claros, que no es el caso de la serie temporal en estudio de de magnitud y produndidad de sismos en el municipio de los Santos, Santander, según los resultados de la prueba ADF. 


## Magnitud 

```{r}
library(forecast)

indice.ts2 <- head(indice.ts, -30)

# Ajustar el modelo ARIMA
modelo_magnitud_arima <- auto.arima(indice.ts2)

# Resumen del modelo
summary(modelo_magnitud_arima)

```
El modelo ARIMA(1,0,1) ajustado a la serie temporal indice.ts (Magnitud de los sismos) muestra un ajuste adecuado y preciso para los datos. Los coeficientes del modelo, ar1 (0.9439) y ma1 (-0.8268), junto con su media (2.9468), son significativos, como lo indican sus bajos errores estándar. Las medidas estadísticas del modelo AIC (5001.51), AICc (5001.52) y BIC (5024.89), sugieren un buen ajuste del modelo a los datos.

Por otra parte, las medidas de error del conjunto de entrenamiento, como RMSE (0.6426) y MAE (0.4929), son bajas, indicando que las predicciones son precisas. Como se evidencia el modelo ARIMA(1,0,1) proporciona un ajuste robusto y confiable para la serie temporal en la variable de (Magnitud).


```{r}
# Hacer predicciones para los próximos 4 meses utilizando la función forecast del paquete forecast
pronostico_magnitud_arima <- forecast::forecast(modelo_magnitud_arima, h=30)

# Graficar las predicciones
plot(pronostico_magnitud_arima, main="Pronóstico de Magnitud de Sismos", ylab="Magnitud", xlab="Tiempo")
```


```{r}
library(forecast)
library(tseries)

# Ajustar el modelo ARIMA automáticamente
modelo_magnitud_arima <- auto.arima(sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML)

# Mostrar el resumen del modelo
summary(modelo_magnitud_arima)

```
```{r}
# Gráficos de diagnóstico
tsdiag(modelo_magnitud_arima)

# Gráfico de los residuos
plot(residuals(modelo_magnitud_arima), main="Residuos del Modelo ARIMA")

# ACF de los residuos
Acf(residuals(modelo_magnitud_arima), main="ACF de los Residuos del Modelo ARIMA")

```

```{r}
# Diagnóstico del modelo ARIMA: revisión de residuos
checkresiduals(modelo_magnitud_arima)
```


```{r}
# Calcular pronósticos dentro de la muestra
fitted_values <- fitted(modelo_magnitud_arima)
actual_values <- sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML

# Calcular errores
errors <- actual_values - fitted_values

# Calcular métricas de error
rmse <- sqrt(mean(errors^2))
mae <- mean(abs(errors))
mape <- mean(abs(errors / actual_values)) * 100

# Mostrar las métricas de error
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%\n")

```

```{r}
# Prueba de Ljung-Box para autocorrelaciones en los residuos
Box.test(residuals(modelo_magnitud_arima), lag=10, type="Ljung-Box")

```


La gráfica presenta el pronóstico de la magnitud de los sismos para los próximos 4 meses basado en un modelo ARIMA ajustado a los datos históricos desde 2011 hasta 2018. La consistencia entre las predicciones y los datos históricos sugiere que el modelo ha capturado bien los patrones de la serie temporal y los intervalos de confianza indican una mayor certeza en las predicciones a corto plazo y mayor incertidumbre en el largo plazo.


```{r}
# Residuos del modelo
residuales_magnitud_arima <- residuals(modelo_magnitud_arima)

# Prueba de Shapiro-Wilk para normalidad
shapiro.test(residuales_magnitud_arima)

# Prueba de Ljung-Box para autocorrelación
Box.test(residuales_magnitud_arima, type="Ljung-Box")
```
Los resultados de las pruebas estadísticas aplicadas a los residuos del modelo ARIMA cuando la variable es Magnitud (ML), evidencia que la prueba de normalidad de Shapiro-Wilk arroja  un p-value = 2.2e-16. Este resultado indica que los residuos no siguen una distribución normal. Por otro lado, la prueba de autocorrelación de Ljung-Box muestra un p-value = 0.5756. El cual es mayor a 0.05, sugiriendo que no hay evidencia suficiente para rechazar la hipótesis nula de que los residuos son independientes y no están autocorrelacionados. Por tanto, se determina que el modelo ARIMA ajustado es adecuado en términos de independencia de los residuos.

## Profundidad 

```{r}

P_indice.ts2 <- head(P_indice.ts, -30)

# Ajustar el modelo ARIMA
modelo_profundidad_arima <- auto.arima(P_indice.ts2)

# Resumen del modelo
summary(modelo_profundidad_arima)
```

El modelo ARIMA(3,1,1) ajustado a la serie temporal P_indice.ts (Profundidad de los sismos) muestra un ajuste adecuado y preciso para los datos. Los coeficientes del modelo, ar1 (0.0102), ar2 (0.0169), ar3 (0.0439) y ma1 (-0.9775), son significativos, como lo indican los errores estándar bajos. Las medidas estadísticas del modelo AIC (18053.81), AICc (18053.83) y BIC (18083.04) sugieren un buen ajuste del modelo a los datos.

Por otra parte, las medidas de error del conjunto de entrenamiento, como RMSE (8.2595) y MAE (3.6201), son aceptables, indicando que las predicciones son razonablemente precisas. Estos resultados muestran que el modelo ARIMA(3,1,1) proporciona un ajuste robusto y confiable para la serie temporal en la variable de profundidad de los sismos en el muncipio de los Santos, Santander.

```{r}
# Hacer predicciones para los próximos 4 meses utilizando la función forecast del paquete forecast
pronostico_profundidad_arima <- forecast::forecast(modelo_profundidad_arima, h=30)

# Graficar las predicciones
plot(pronostico_profundidad_arima, main="Pronóstico de Profundidad de Sismos", ylab="Profundidad", xlab="Tiempo")
```
La gráfica presenta el pronóstico de la profundidad de los sismos para los próximos 4 meses basado en un modelo ARIMA ajustado a los datos históricos desde 2011 hasta 2018. La consistencia entre las predicciones y los datos históricos sugiere que el modelo ha capturado bien los patrones de la serie temporal y los intervalos de confianza indican una mayor certeza en las predicciones a corto plazo y mayor incertidumbre en el largo plazo.

```{r}
# Ajustar el modelo ARIMA automáticamente
modelo_profundidad_arima <- auto.arima(sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD)

# Mostrar el resumen del modelo
summary(modelo_profundidad_arima)
```
```{r}
# Gráficos de diagnóstico
tsdiag(modelo_profundidad_arima)

# Gráfico de los residuos
plot(residuals(modelo_profundidad_arima), main="Residuos del Modelo ARIMA")

# ACF de los residuos
Acf(residuals(modelo_profundidad_arima), main="ACF de los Residuos del Modelo ARIMA")

```
```{r}
# Diagnóstico del modelo ARIMA: revisión de residuos
checkresiduals(modelo_profundidad_arima)
```


```{r}
# Residuos del modelo
residuales_profundidad_arima <- residuals(modelo_profundidad_arima)

# Prueba de Shapiro-Wilk para normalidad
shapiro.test(residuales_profundidad_arima)

# Prueba de Ljung-Box para autocorrelación
Box.test(residuales_profundidad_arima, type="Ljung-Box")
```
Los resultados de las pruebas estadísticas aplicadas a los residuos del modelo ARIMA cuando la variable es Profundidad, evidencia que la prueba de normalidad de Shapiro-Wilk arroja  un p-value = 2.2e-16. Este resultado indica que los residuos no siguen una distribución normal. Por otro lado, la prueba de autocorrelación de Ljung-Box muestra un p-value = 0.972. El cual es mayor a 0.05, sugiriendo que no hay evidencia suficiente para rechazar la hipótesis nula de que los residuos son independientes y no están autocorrelacionados. Por tanto, se determina que el modelo ARIMA ajustado es adecuado en términos de independencia de los residuos.

# <span style="color:blue">**Algoritmo Facebook's Prophet**</span>

A continuación se utiliza una herramienta que ayuda a predecir lo que va a pasar en el futuro usando datos del pasado. Esta herramienta fue creada por Facebook y es muy buena para trabajar con datos que cambian de manera regular como los datos de los sismos. A continuación se utiliza el algoritmo Prophet para la variable magnitud y profundidad de los sismos.

## Magnitud

```{r}
# Cargar el paquete
library(prophet)
library(ggplot2)
library(forecast)

# Asumiendo que los datos están en un data.frame llamado sismo
# Convertir las fechas y profundidades en un formato adecuado para Prophet
data_magnitud <- data.frame(
  ds = as.Date(sismo_4_max_completo_filtrado$FECHA), 
  y = sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML
)

# Quitar los últimos 30 días de los datos
train_data_magnitud <- head(data_magnitud, -30)

# Ajustar el modelo Prophet con los datos de entrenamiento
modelo_magnitud_prophet <- prophet(train_data_magnitud)

# Hacer predicciones para los próximos 30 días
future <- make_future_dataframe(modelo_magnitud_prophet, periods = 30)
pronostico_magnitud_prophet <- predict(modelo_magnitud_prophet, future)

# Graficar las predicciones
plot(modelo_magnitud_prophet, pronostico_magnitud_prophet) +
  labs(title = "Pronóstico de Magnitud de Sismos", y = "Magnitud", x = "Tiempo")
```
```{r}
# Calcular los residuos
residuales_magnitud_prophet <- data_magnitud$y[1:nrow(train_data_magnitud)] - pronostico_magnitud_prophet$yhat[1:nrow(train_data_magnitud)]

# Test de Shapiro-Wilk para normalidad de los residuos
shapiro_test <- shapiro.test(residuales_magnitud_prophet)
print(shapiro_test)

# Test de Box-Ljung para independencia de los residuos
box_ljung_test <- Box.test(residuales_magnitud_prophet, lag = 20, type = "Ljung-Box")
print(box_ljung_test)

# Graficar los residuos
residuals_df <- data.frame(time = train_data_magnitud$ds, residuals = residuales_magnitud_prophet)
ggplot(residuals_df, aes(x = time, y = residuals)) +
  geom_line() +
  labs(title = "Residuos del Modelo Prophet", x = "Tiempo", y = "Residuos")

# Graficar la función de autocorrelación de los residuos
acf(residuales_magnitud_prophet, main = "ACF de los Residuos del Modelo Prophet")

```

La primera es la prueba aplicada es la de normalidad de Shapiro-Wilk, cuyo valor p es significativamente menor que 0.05 (p < 2.2e-16), indicando que los residuos no siguen una distribución normal. La segunda es la prueba de Box-Ljung, que muestra un valor p de 0.01567, también menor que 0.05, lo que sugiere la presencia de autocorrelación en los residuos. 

## Profundidad

```{r}
# Cargar el paquete
library(prophet)

# Asumiendo que los datos están en un data.frame llamado sismo_4_max_completo_filtrado
# Convertir las fechas y profundidades en un formato adecuado para Prophet
data_profundidad <- data.frame(
  ds = as.Date(sismo_4_max_completo_filtrado$FECHA), 
  y = sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD
)

# Quitar los últimos 30 días de los datos
train_data_profundidad <- head(data_profundidad, -30)

# Ajustar el modelo Prophet con los datos de entrenamiento
modelo_profundidad_prophet <- prophet(train_data_profundidad)

# Hacer predicciones para los próximos 30 días
future <- make_future_dataframe(modelo_profundidad_prophet, periods = 30)
pronostico_profundidad_prophet <- predict(modelo_profundidad_prophet, future)

# Graficar las predicciones
plot(modelo_profundidad_prophet, pronostico_profundidad_prophet) +
  labs(title = "Pronóstico de Profundidad Mínima de Sismos", y = "Profundidad (km)", x = "Tiempo")

```

```{r}
# Calcular los residuos
residuales_profundidad_prophet <- train_data_profundidad$y - predict(modelo_profundidad_prophet, train_data_profundidad)$yhat

# Test de Shapiro-Wilk para normalidad de los residuos
shapiro_test <- shapiro.test(residuales_profundidad_prophet)
print(shapiro_test)

# Test de Box-Ljung para independencia de los residuos
box_ljung_test <- Box.test(residuales_profundidad_prophet, lag = 20, type = "Ljung-Box")
print(box_ljung_test)

# Graficar los residuos
residuals_df <- data.frame(time = train_data_profundidad$ds, residuals = residuales_profundidad_prophet)
ggplot(residuals_df, aes(x = time, y = residuals)) +
  geom_line() +
  labs(title = "Residuos del Modelo Prophet para Profundidad", x = "Tiempo", y = "Residuos")

# Graficar la función de autocorrelación de los residuos
acf(residuales_profundidad_prophet, main = "ACF de los Residuos del Modelo Prophet para Profundidad")

```


La gráfica muestra el pronóstico de la profundidad de los sismos en el tiempo utilizando el modelo Prophet. Los puntos negros corresponden a las profundidades observadas de los sismos, mientras que la línea azul muestra la tendencia central pronosticada por el modelo. Las bandas de color azul claro alrededor de la línea central indican los intervalos de confianza del pronóstico, reflejando la incertidumbre del modelo en sus predicciones. La gráfica evidencia que la profundidad de los sismos se ha mantenido relativamente constante a lo largo del tiempo, con algunos valores atípicos que se observan principalmente por debajo de los 100 kilómetros de profundidad.


```{r}
# Evaluar los residuos
residuales_profunidad_prophet <- data_profundidad$y - pronostico_profundidad_prophet$yhat[1:length(data_profundidad$y)]

# Prueba de Shapiro-Wilk para normalidad
shapiro.test(residuales_profunidad_prophet)

# Prueba de Ljung-Box para autocorrelación
Box.test(residuales_profunidad_prophet, type = "Ljung-Box")
```
La prueba de normalidad de Shapiro-Wilk presenta un valor W de 0.42744 y un valor p significativamente menor que 2.2e-16, indicando que los residuos no siguen una distribución normal. Por otro lado, la prueba de Box-Ljung, con un valor X-squared de 1.2332, 1 grado de libertad, y un valor p de 0.2668, sugiere que no hay una autocorrelación significativa en los residuos (dado que el valor p es mayor que 0.05). Aunque los residuos no son normales, no muestran evidencia de autocorrelación, lo que indica que el modelo captura adecuadamente la independencia temporal de los datos.

___________________________________________________________________________

# <span style="color:blue">**Modelo Elman**</span>

## Modelo Elman Profundidad

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_profundidad

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

elman_model <- elman(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(elman_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Profundidad",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Elman Profundidad con todo el historico', xlab = 'Fecha', ylab = 'Profundidad')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)

```


## Modelo Elman Magnitud

```{r}
#prueba de concepto Elman
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_magnitud

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

elman_model <- elman(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(elman_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Magnitud",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Elman Magnitud con todo el historico', xlab = 'Fecha', ylab = 'Magnitud')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)
```



## Modelo Jordan Profundidad

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_profundidad

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

jordan_model <- jordan(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(jordan_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Profundidad",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Jordan Profundidad con todo el historico', xlab = 'Fecha', ylab = 'Profundidad')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)
```

## Modelo Jordan Magnitud

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_magnitud

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

jordan_model <- jordan(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(jordan_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Magnitud",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Jordan Magnitud con todo el historico', xlab = 'Fecha', ylab = 'Magnitud')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)

```



# <span style="color:blue">**Bibliografía**</span>

**Información sismica:**
https://www.infobae.com/colombia/2024/06/12/sismo-hoy-se-registro-un-temblor-en-el-municipio-de-los-santos-en-santander/
https://www.eltiempo.com/colombia/otras-ciudades/temblores-en-colombia-los-santos-el-municipio-donde-hay-mas-sismos-por-que-772495

**Base de datos:**
https://sish.sgc.gov.co/visor/
https://sish.sgc.gov.co/visor/sesionServlet?metodo=irAMunicipio&idDepartamento=68&idMunicipio=68418&cuadranteXMin=&cuadranteXMax=&cuadranteYMin=&cuadranteYMax=

**Descripción de las escalas**

HORA_UTC, MAGNITUD LOCAL, MAGNITUD DE MOMENTO, RMS, GAP
https://ds.iris.edu/latin_am/evlist.phtml?region=dom#:~:text=FECHA%20%2D%20HORA%20(UTC)%3A&text=La%20hora%20es%20expresada%20en,siete%20horas%20de%20Costa%20Rica.

http://www.ssn.unam.mx/jsp/reportesEspeciales/Magnitud-de-un-sismo.pdf

**Series de tiempo**
https://www.enae.es/curso/series-temporales?gad_source=1&gclid=CjwKCAjw7NmzBhBLEiwAxrHQ-ZlAegMbh59V8uZVHOTqUmvNTBkVxtmoUpLOH4wtw9Gwys1dWXmLSxoC9uUQAvD_BwE&_adin=02021864894







