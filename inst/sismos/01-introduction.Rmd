
# <span style="color:blue">**Contenido de la Data**</span>

```{r include = FALSE}
library(readr) # leer .csv
library(dplyr) # procesamiento de datos
library(skimr) # muestra variables categoricas y numericas
```

A continuación se presenta la base de datos a utilizar en la investigación. 


```{r}
#sismo <- read_csv("C:/Users/victo/Documents/Maestría/1.2. Segundo semestre/Series de tiempo/data_sismo.csv")#Victoria
sismo <- read_csv("../../data_sismo.csv")#wladimir
#sismo <- read_csv("D:/Documentos/GitHub/Series_de_tiempo/data_sismo.csv")#Mario
sismo <- mutate_if(sismo, is.character, tolower) # pasamos a minúsculas
glimpse(sismo)
```

## <span style="color:darkgreen">**Observación de los datos**</span>


### **El Tiempo Universal Coordinado (HORA_UTC):**
Es una escala de tiempo que es mantenida por los laboratorios de tiempo de todo el mundo y es determinada por relojes atómicos de alta precisión. El tiempo UTC es preciso a aproximadamente un nanosegundo (millonésima parte de un segundo) por día.

### **Magnitud Local (Ml):**
Donde A es la máxima amplitud de la traza registrada y Ao la amplitud máxima que sería producida por un sismo patrón, siendo éste aquel que produciría una deflexión de 0.001 mm en un sismógrafo ubicado a 100 km del epicentro.

### **Magnitud de momento (Mw):**
Esta magnitud es la más robusta; a diferencia de ML, mB y MS, la escala Mw no se satura, por lo que hoy en día es la más confiable y la más usada por las agencias dedicadas a la detección de sismos. También es la magnitud más usada por científicos para comparar los tamaños entre sismos.

### **Root Mean Square (RMS):**
Es la medida del error, comparando la diferencia promedio entre el tiempo de arribo teórico y el tiempo de arribo observado en segundos, utilizando las lecturas de los sismogramas.

### **Brecha sísmica (GAP):**

Zona geológica en la que no ha ocurrido un sismo fuerte durante un periodo prolongado de tiempo.


## <span style="color:darkgreen">**Descripción Datos** </span>

```{r}
skim(sismo)
```
La profundidad de sismos en kilómetros muestra una media de 145.0610908, con una desviación estándar de 5.16222274.Por su aprte, las magnitudes Ml y Mw, tienen medias de 1.8909980 y 3.4296736 respectivamente. La magnitud Mw muestra una tasa de completitud más baja, con un 5.97% de datos faltantes.

El número de fases registradas por evento tiene una media de 9.8856949, el RMS (Root Mean Square) y GAP (Brecha) presentan una media de 0.3912964 y 144.3370952 respectivamente.

## <span style="color:darkgreen">**Imputar Datos**</span>

* Existen **31826** datos faltantes **NA** para la variable **Magnitud Mw** por tanto se decide remover de la base de datos 
* Para las demás variables de tipo categórico, fecha, tiempo, y numérico no hay datos faltantes
* Las variables categóricas corresponden a la descripción del departamento de Santander, en su municipio de Los_Santos y para la columna estado se encuentran todos los datos en revisado, por tanto se procede a removerlas de la data original sismo
* Para el ejercicio académico se ha decidido remover las variables de error de latitud, longitud, y profundidad
* También se renombra las variables que contienen comillas en su estructura de columnas

```{r}
sismo_2 <- sismo
# las columnas retiradas fueron 7,8,9,13,14,15,16
sismo_2 <- sismo_2 [, c(1,2,3,4,5,6,10,11,12)] # data con 9 variables
colnames(sismo_2)[3] <-"LATITUD"  # renombrar variable
colnames(sismo_2)[4] <-"LONGITUD"  # renombrar variable
colnames(sismo_2)[5] <-"PROFUNDIDAD"  # renombrar variable
colnames(sismo_2)[6] <-"MAGNITUD_ML"  # renombrar variable
colnames(sismo_2)[7] <-"NUM_FASES"  # renombrar variable
colnames(sismo_2)[8] <-"RMS"  # renombrar variable
colnames(sismo_2)[9] <-"GAP"  # renombrar variable
head(sismo_2)
```

# <span style="color:blue">**Variable Numéricas**</span>

Los siguientes gráficos muestran la distribución de la latitud, longitud, profundidad, magnitud, número de fases,  Root Mean Square ( RMS) y la brecha sismica (GAP) de los sismos en el municipio de Los Santos, Santander. Cada gráfico representa la frecuencia de sismos en el eje Y un dato específico relacionado con cada una de las variables en el eje x.

La profundidad presenta una media de 145 km, con relación a la magnitud es una forma asimetrica a la derecha con una media  de  1.8, el número de fases es una forma asimetrica a la izquierda y tiene una media de 9.8, por su parte el RMS y el GAP presentan una forma multimodal ya que aparecen varios picos y sus medias son de 0.3 y de 144 respectivamente.

```{r include = FALSE}
library(ggpubr) # visualización
library(plotly) # visualización
library(CGPfunctions) # gráfica cuantitativas
library(ggplot2)
```

```{r}
g1 = ggplot(sismo_2, aes(x = LATITUD)) + geom_histogram(fill="royalblue") + theme_gray()
g2 = ggplot(sismo_2, aes(x = LONGITUD)) + geom_histogram(fill="royalblue") + theme_gray()
g3 = ggplot(sismo_2, aes(x = PROFUNDIDAD)) + geom_histogram(fill="royalblue") + theme_gray()
g4 = ggplot(sismo_2, aes(x = MAGNITUD_ML)) + geom_histogram(fill="royalblue") + theme_gray()
g5 = ggplot(sismo_2, aes(x = NUM_FASES)) + geom_histogram(fill="royalblue") + theme_gray()
g6 = ggplot(sismo_2, aes(x = RMS)) + geom_histogram(fill="royalblue") + theme_gray()
g7 = ggplot(sismo_2, aes(x = GAP)) + geom_histogram(fill="royalblue") + theme_gray()


ggarrange(g1, g2, g3, g4, g5, g6, g7, labels = c("A", "B", "C","D", "E", "F","G"), ncol = 2, nrow = 2)
```

# <span style="color:darkgreen">**Variable Serie Tiempo** </span>

```{r setup, include = FALSE}
library(forecast) #predicción
library(tseries)  #análisis de series de tiempo
library(timsac)
library(changepoint) #detectar puntos de cambios
```

**Análisis de la Data**

A continuación se se seleccionan las variables de análisis para el presente ejercicio:

Profundidad: esta variable se selcciono dado que representa la profundidad del foco sísmico y este influye en cómo se siente un terremoto en la superficie, los terremotos superficiales, son aquellos que tienen un foco a menos de 70 km de profundidad, estos generalmente causan mas daño ya que la energía que liberan no se dispera tanto antes de llegar a la superficie. 

Magnitud: la magnitud en Colombia se reorta utilizando la escala de Richter, esta medida permite conocer cuanta es la energía liberada por un sismo.

```{r}
sismo_3 <- sismo_2 # copiamos data2
sismo_3 <- sismo_3 [, c(1,5,6)] # data con 3 variables 1:fecha, 5:profundidad, 6:magnitud
#sismo_3$fecha_hora <- paste(sismo_3$FECHA," ",sismo_3$HORA_UTC)# unir columnas 1 y 2
#sismo_3$fecha_hora <- as.POSIXct(sismo_3$fecha_hora) # convertir a tipo date time
#sismo_3$FECHA_UNIX <- as.POSIXct(sismo_3$FECHA)
sismo_3 <- sismo_3[order(sismo_3$FECHA), ] #ordenamo sismo_3 de menor a mayor
head(sismo_3,2)
```

Se agrupan las fechas para obtener un dato único por día, con relación a la magnitud se decidió calcular el maximo de cada día para conocer el sismo que libera la mayor cantidad de energía y con relación a la profundidad se decidió calcular el minimo con el fin de determianr el sismo que esta mas cerca a la superficie y puede causar mas daño.


```{r}
sismo_4_max <- sismo_3 %>% # Agrupamos por fecha y obtenemos el máximo de la magnitud para cada fecha
  group_by(FECHA) %>% 
  summarise(MAX_MAGNITUD_ML = max(MAGNITUD_ML),
            MIN_PROFUNDIDAD = min(PROFUNDIDAD))
head(sismo_4_max, 2)
```

Dado que no hay información para todos los días del año entre el 28 de febrero de 2011 y el 28 de febrero de 2018 primero se creo un data frame con todas las fechas en ese rango y posteriormente los datos faltantes en las variables MAGNITUD Y PROFUNCIDAD se llenaron de la siguiente forma:

Profundidad: la profundidad se decio llenar con la media que es 145.0610908. Esta decición esta fundamentada en que la revisar la gráfica de series de tiempo, si se llenaran con profundidad 0 generaria mucho ruido y no permitiria visualizar adecuadamente los simso que realmente presentan una profundida baja y cercana a la superficie.

Magnitud: la magnitud se decidio llenar con 0.

```{r}
# Crear un data frame con todas las fechas en el rango deseado
todas_las_fechas <- data.frame(FECHA = seq(as.Date("2011-02-28"), as.Date("2018-02-28"), by = "day"))

sismo_4_max_completo <- todas_las_fechas %>%
  left_join(sismo_4_max, by = "FECHA") %>%
  mutate(MAX_MAGNITUD_ML = ifelse(is.na(MAX_MAGNITUD_ML), 0, MAX_MAGNITUD_ML),
         MIN_PROFUNDIDAD = ifelse(is.na(MIN_PROFUNDIDAD), 145.0610908, MIN_PROFUNDIDAD))

# Filtrar desde el 28 de febrero de 2017 hasta el 28 de febrero de 2018
sismo_4_max_completo_filtrado <- sismo_4_max_completo %>%
  filter(FECHA >= as.Date("2017-02-28") & FECHA <= as.Date("2018-02-28"))

head(sismo_4_max_completo_filtrado, 2)
```

Se revisa que el número de filas concurde para comprobar que se encuentran todos los días entre el 28 de febrero de 2011 y el 28 de febrero de 2018.

```{r}
nrow(todas_las_fechas)
```

```{r}
nrow(sismo_4_max_completo_filtrado)
```
```{r}

```




**Serie de tiempo Magnitud**

```{r}
indice.ts <- ts(sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML,start = c(2017,2),end = c(2018,2), frequency = 365)
#head(indice.ts,10) 
head(indice.ts)
```

**Datos de la serie**

```{r}
"Tipo ts"
class(indice.ts)
"Inicio serie"
start(indice.ts)
"fin serie"
end(indice.ts)
```

**Gráfica de la serie**


```{r}
hist(indice.ts,main="",ylab="valor", col='orange', xlab ="MAGNITUD_ML")
title(main="MAGNITUD DEL SISMO EN EL TIEMPO")
```
La distribución de la magnitud de los sismos en el municipio de Los Santos Santander evidencia que la mayoria de los sismos presentados son de magnitud baja y no presnetan un mayor riezgo para la población. Hay presencia de sismos de magnitud fuerte sin embargo hay que revisar la profundidad de estos para determinar si causan daños a la población.


```{r}
plot(indice.ts,main="",ylab="valor", col='orange', xlab ="FECHA")
title(main="MAGNITUD DEL SISMO EN EL TIEMPO")
```

**Serie de tiempo Profundidad**

```{r}
P_indice.ts <- ts(sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD,start = c(2017,2),end = c(2018,2), frequency = 365)
#head(indice.ts,10) 
head(P_indice.ts)
```

**Datos de la serie**

```{r}
"Tipo ts"
class(P_indice.ts)
"Inicio serie"
start(P_indice.ts)
"fin serie"
end(P_indice.ts)
```

**Gráfica de la serie**

```{r}
hist(P_indice.ts,main="",ylab="valor", col='saddlebrown', xlab ="PROFUNDIDA")
title(main="PROFUNDIDAD DEL SISMO (KM) EN EL TIEMPO")
```
La distribución de la profundiad de los sismos en el municipio de Los Santos Santander evidencia que la mayoria de los sismos presentados son de alta profunidad y no presnetan un mayor riezgo para la población. 



```{r}
plot(P_indice.ts,main="",ylab="valor", col='saddlebrown', xlab ="FECHA")
title(main="PROFUNDIDAD DEL SISMO (KM) EN EL TIEMPO")
```


# Gráfica de sismos 

**Profundidad**

```{r}
library(ggplot2)
library(TSstudio)


data_profundidad_from_2012 <- sismo_4_max_completo[-(1:308), ]

data_serie <- ts(data_profundidad_from_2012$MIN_PROFUNDIDAD, frequency=365, start=2012)
plot(data_serie)

autoplot(data_serie)+
        labs(title = "Serie de tiempo",       
             x = "Tiempo",
             y = "Valor",
             colour = "#00a0dc")+
        theme_bw() 


fit <- decompose(data_serie, type='additive')

autoplot(data_serie, series="Serie tiempo") + 
        autolayer(trendcycle(fit), series="Tendencia") +
        labs(title = "Serie de tiempo",      
             x = "Tiempo",
             y = "Valor"
        ) + 
        theme_bw()


ggseasonplot(data_serie)

ts_seasonal(data_serie, type = "all")
```


**Magnitud**

```{r}
library(ggplot2)
library(TSstudio)

data_magnitud_from_2012 <- sismo_4_max_completo[-(1:308), ]


data_serie <- ts(data_magnitud_from_2012$MAX_MAGNITUD_ML, frequency=365, start=2012)
plot(data_serie)

autoplot(data_serie)+
        labs(title = "Serie de tiempo",       
             x = "Tiempo",
             y = "Valor",
             colour = "#00a0dc")+
        theme_bw() 


fit <- decompose(data_serie, type='additive')

autoplot(data_serie, series="Serie tiempo") + 
        autolayer(trendcycle(fit), series="Tendencia") +
        labs(title = "Serie de tiempo",      
             x = "Tiempo",
             y = "Valor"
        ) + 
        theme_bw()


ggseasonplot(data_serie)


ts_seasonal(data_serie, type = "all")
```



# <span style="color:blue">**Holt-Winter**</span>

A continuación, se aplica la metolodgía Holt-Winter y de suavizamiento a la variable tiempo. Esta técnica de análisis de series temporales se utiliza para predecir datos con componentes de tendencia y estacioanlidad.

## Magnitud

```{r}
library(aTSA)

# Transformar la serie (si es necesario)
adf.test(diff(indice.ts))
```

## Profundidad

```{r}
library(aTSA)

# Transformar la serie (si es necesario)
adf.test(diff(P_indice.ts))
```


Teniendo en cuenta los resultados del test de Dickey-Fuller aumentado (ADF), se evidencio que todos los valores del estadístico ADF son negativos y los valores p son 0.01 para todos tipos de prueba: 

* Tipo 1: sin deriva y sin tendencia
* Tipo 2: con deriva y sin tendencia
* Tipo 3: con deriva y tendencia

Con base en lo anterior hay suficiente evidencia para rechazar la hipótesis nula de una raíz unitaria, concluyendo que la serie temporal es estacionaria. 

# <span style="color:blue">**ARIMA**</span>

A continuación, se aplica la metodología Box-Jenkins también conocida como ARIMA, este es un enfoque sistemático para construir modelos de series temporales que pueden predecir valores futuros basados en valores pasados y se utiliza especialmente cuando los datos no tienen una tendencia clara o una estacionalidad simple como es el caso de nuestros datos. 

Teniendo en cuenta lo mencionado anteriormente y dado que el modelo ARIMA es particularmente adecuado para series temporales estacionarias, se justifica su uso en lugar del modelo Holt-Winters. 

Este último es más adecuado para datos con componentes de tendencia y estacionalidad claros, que no es el caso de la serie temporal en estudio de de magnitud y produndidad de sismos en el municipio de los Santos, Santander, según los resultados de la prueba ADF. 


## Magnitud 

```{r}
library(forecast)

indice.ts2 <- head(indice.ts, -30)

# Ajustar el modelo ARIMA
modelo_magnitud_arima <- auto.arima(indice.ts2)

# Resumen del modelo
summary(modelo_magnitud_arima)

```
El modelo ARIMA(2,1,2) ajustado a la serie temporal indice.ts2 de (magnitud de los sismos) presenta los siguientes coeficientes estimados: AR1 (-0.9609), AR2 (-0.0635), MA1 (-0.0565) y MA2 (-0.9072), todos con errores estándar que sugieren una precisión razonable en las estimaciones. Las medidas de error en el conjunto de entrenamiento incluyen un ME de -0.048, un RMSE de 0.578, y un MAE de 0.458, indicando un ajuste razonable del modelo con errores moderadamente bajos. El MAPE de 16.44% sugiere que el modelo tiene una precisión aceptable en términos relativos, aunque no excelente.


```{r}
# Hacer predicciones para los próximos 4 meses utilizando la función forecast del paquete forecast
pronostico_magnitud_arima <- forecast::forecast(modelo_magnitud_arima, h=30)

# Graficar las predicciones
plot(pronostico_magnitud_arima, main="Pronóstico de Magnitud de Sismos", ylab="Magnitud", xlab="Tiempo")
```
Se presenta la serie temporal de la magnitud de los sismos desde principios de 2017 hasta principios de 2018, junto con el pronóstico de magnitud para los últimos 30 días del período analizado. La línea azul representa las predicciones del modelo Prophet, mientras que las áreas sombreadas en gris claro y oscuro representan los intervalos de confianza al 80% y 95%, respectivamente, las bandas de confianza más amplias hacia el final del período indican una mayor incertidumbre en las predicciones futuras.


```{r}
library(forecast)
library(tseries)

# Ajustar el modelo ARIMA automáticamente
modelo_magnitud_arima <- auto.arima(sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML)

# Mostrar el resumen del modelo
summary(modelo_magnitud_arima)

```
El modelo ARIMA de magnitud muestra un ajuste razonable, aunque con ciertas limitaciones en la predicción debido a la variabilidad de los datos sísmicos. 

```{r}
# Gráficos de diagnóstico
tsdiag(modelo_magnitud_arima)

# Gráfico de los residuos
plot(residuals(modelo_magnitud_arima), main="Residuos del Modelo ARIMA")

# ACF de los residuos
Acf(residuals(modelo_magnitud_arima), main="ACF de los Residuos del Modelo ARIMA")

```
Las dos gráficas indican que el modelo ARIMA está bien especificado, ya que los residuos no presentan autocorrelación significativa y están distribuidos de manera aleatoria alrededor de cero. Sin embargo, la presencia de algunos picos sugiere que podría haber eventos atípicos o anomalías pero dado que en los sismos es normal, no se consideran datos atípicos.


```{r}
# Diagnóstico del modelo ARIMA: revisión de residuos
checkresiduals(modelo_magnitud_arima)
```
La gráfica compuesta presenta un análisis de los residuos del modelo ARIMA(2,1,2) ajustado para predecir la magnitud de los sismos. La serie temporal de los residuos (parte superior) muestra que los residuos están distribuidos alrededor de cero sin patrones evidentes, aunque con algunos picos ocasionales. La función de autocorrelación (ACF) de los residuos (parte inferior izquierda) revela que casi todos los valores de autocorrelación caen dentro de las bandas de confianza, indicando que no hay autocorrelación significativa en los residuos. Esto sugiere que el modelo ha capturado bien las dependencias temporales en los datos. En conjunto, estos análisis indican que el modelo ARIMA(2,1,2) es adecuado, ya que los residuos no presentan autocorrelación significativa y siguen una distribución aproximadamente normal, aunque hay algunos picos que podrían ser eventos atípicos.

```{r}
# Calcular pronósticos dentro de la muestra
fitted_values <- fitted(modelo_magnitud_arima)
actual_values <- sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML

# Calcular errores
errors <- actual_values - fitted_values

# Calcular métricas de error
rmse <- sqrt(mean(errors^2))
mae <- mean(abs(errors))
mape <- mean(abs(errors / actual_values)) * 100

# Mostrar las métricas de error
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("MAPE:", mape, "%\n")

```
En conjunto, estas métricas sugieren que el modelo ARIMA(2,1,2) tiene un rendimiento razonablemente bueno para predecir la magnitud de los sismos. 


```{r}
# Prueba de Ljung-Box para autocorrelaciones en los residuos
Box.test(residuals(modelo_magnitud_arima), lag=10, type="Ljung-Box")

```

Los residuos se consideran independientes, lo que sugiere que el modelo ARIMA ha capturado adecuadamente las dependencias temporales en los datos. 

```{r}
# Residuos del modelo
residuales_magnitud_arima <- residuals(modelo_magnitud_arima)

# Prueba de Shapiro-Wilk para normalidad
shapiro.test(residuales_magnitud_arima)

# Prueba de Ljung-Box para autocorrelación
Box.test(residuales_magnitud_arima, type="Ljung-Box")
```
Los resultados de los dos tests muestran que los residuos son independientes, lo que indica que el modelo ha capturado adecuadamente las dependencias temporales en los datos. 


## Profundidad 

```{r}

P_indice.ts2 <- head(P_indice.ts, -30)

# Ajustar el modelo ARIMA
modelo_profundidad_arima <- auto.arima(P_indice.ts2)

# Resumen del modelo
summary(modelo_profundidad_arima)
```
El modelo ARIMA(0,1,1) ajustado para la serie temporal P_indice.ts2 (profundidad) muestra que el término de media móvil es significativo y que el modelo ha capturado adecuadamente las dependencias temporales, como lo indica la baja autocorrelación en los residuos. 


```{r}
# Hacer predicciones para los próximos 4 meses utilizando la función forecast del paquete forecast
pronostico_profundidad_arima <- forecast::forecast(modelo_profundidad_arima, h=30)

# Graficar las predicciones
plot(pronostico_profundidad_arima, main="Pronóstico de Profundidad de Sismos", ylab="Profundidad", xlab="Tiempo")
```

En la serie temporal, la mayoría de los sismos ocurren a profundidades cercanas a 145 km, con algunas anomalías de eventos sísmicos a profundidades significativamente menores, sin embargo dado el contexto no se consideran datos atipicos o anomalias. El pronóstico, representado por la línea azul y las bandas de confianza sombreadas en gris claro y oscuro (al 80% y 95%, respectivamente), indica que se espera que las profundidades de los sismos se mantengan en niveles similares a los observados anteriormente, alrededor de 145 km. 

```{r}
# Ajustar el modelo ARIMA automáticamente
modelo_profundidad_arima <- auto.arima(sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD)

# Mostrar el resumen del modelo
summary(modelo_profundidad_arima)
```
El modelo ARIMA para profundidad muestra que los residuos no presentan autocorrelación significativa y el coeficiente MA1 es altamente significativo. Sin embargo, las métricas de error indican que las predicciones tienen un margen de error considerable.


```{r}
# Gráficos de diagnóstico
tsdiag(modelo_profundidad_arima)

# Gráfico de los residuos
plot(residuals(modelo_profundidad_arima), main="Residuos del Modelo ARIMA")

# ACF de los residuos
Acf(residuals(modelo_profundidad_arima), main="ACF de los Residuos del Modelo ARIMA")

```

El modelo ha capturado adecuadamente las dependencias temporales en los datos. A pesar de estos valores atípicos debido a los datos de análisis, la mayoría de los residuos se mantienen estables y cercanos a cero, confirmando que el modelo ARIMA es adecuado en su ajuste.


```{r}
# Diagnóstico del modelo ARIMA: revisión de residuos
checkresiduals(modelo_profundidad_arima)
```
En la parte superior, la serie temporal de los residuos muestra que la mayoría de los residuos están cercanos a cero. La gráfica ACF (abajo a la izquierda) muestra que las autocorrelaciones de los residuos están dentro de las bandas de confianza, lo que sugiere que no hay autocorrelación significativa en los residuos, indicando un buen ajuste del modelo. Finalmente, el histograma de los residuos (abajo a la derecha) muestra una distribución aproximadamente normal, aunque con una ligera asimetría y algunos valores extremos. 


```{r}
# Residuos del modelo
residuales_profundidad_arima <- residuals(modelo_profundidad_arima)

# Prueba de Shapiro-Wilk para normalidad
shapiro.test(residuales_profundidad_arima)

# Prueba de Ljung-Box para autocorrelación
Box.test(residuales_profundidad_arima, type="Ljung-Box")
```

El test de Shapiro-Wilk tiene un estadístico W de 0.32756 y un p-valor menor a 2.2e-16, lo que indica que los residuos no siguen una distribución normal. Por otro lado, el test de Box-Ljung tiene un valor de chi-cuadrado de 0.021548 con 1 grado de libertad y un p-valor de 0.8833, sugiriendo que no hay autocorrelación significativa en los residuos.


# <span style="color:blue">**Algoritmo Facebook's Prophet**</span>

A continuación se utiliza una herramienta que ayuda a predecir lo que va a pasar en el futuro usando datos del pasado. Esta herramienta fue creada por Facebook y es muy buena para trabajar con datos que cambian de manera regular como los datos de los sismos. A continuación se utiliza el algoritmo Prophet para la variable magnitud y profundidad de los sismos.

## Magnitud

```{r}
# Cargar el paquete
library(prophet)
library(ggplot2)
library(forecast)

# Asumiendo que los datos están en un data.frame llamado sismo
# Convertir las fechas y profundidades en un formato adecuado para Prophet
data_magnitud <- data.frame(
  ds = as.Date(sismo_4_max_completo_filtrado$FECHA), 
  y = sismo_4_max_completo_filtrado$MAX_MAGNITUD_ML
)

# Quitar los últimos 30 días de los datos
train_data_magnitud <- head(data_magnitud, -30)

# Ajustar el modelo Prophet con los datos de entrenamiento
modelo_magnitud_prophet <- prophet(train_data_magnitud)

# Hacer predicciones para los próximos 30 días
future <- make_future_dataframe(modelo_magnitud_prophet, periods = 30)
pronostico_magnitud_prophet <- predict(modelo_magnitud_prophet, future)

# Graficar las predicciones
plot(modelo_magnitud_prophet, pronostico_magnitud_prophet) +
  labs(title = "Pronóstico de Magnitud de Sismos", y = "Magnitud", x = "Tiempo")
```
La línea azul central representa la predicción del modelo, mientras que las áreas sombreadas en azul claro y oscuro indican los intervalos de confianza del 80% y 95%, respectivamente. Los puntos negros representan las observaciones reales de la magnitud de los sismos durante el período de tiempo mostrado. La mayoría de las observaciones se encuentran dentro de los intervalos de confianza, lo que sugiere que el modelo tiene un buen desempeño en capturar la variabilidad de las magnitudes de los sismos. 

```{r}
# Calcular los residuos
residuales_magnitud_prophet <- data_magnitud$y[1:nrow(train_data_magnitud)] - pronostico_magnitud_prophet$yhat[1:nrow(train_data_magnitud)]

# Test de Shapiro-Wilk para normalidad de los residuos
shapiro_test <- shapiro.test(residuales_magnitud_prophet)
print(shapiro_test)

# Test de Box-Ljung para independencia de los residuos
box_ljung_test <- Box.test(residuales_magnitud_prophet, lag = 20, type = "Ljung-Box")
print(box_ljung_test)

# Graficar los residuos
residuals_df <- data.frame(time = train_data_magnitud$ds, residuals = residuales_magnitud_prophet)
ggplot(residuals_df, aes(x = time, y = residuals)) +
  geom_line() +
  labs(title = "Residuos del Modelo Prophet", x = "Tiempo", y = "Residuos")

# Graficar la función de autocorrelación de los residuos
acf(residuales_magnitud_prophet, main = "ACF de los Residuos del Modelo Prophet")

```

La gráfica que muestra la función de autocorrelación (ACF) de los residuos, indica que casi todos los valores de autocorrelación están dentro de las bandas de confianza, sugiriendo que no hay autocorrelación significativa en los residuos y que el modelo ha capturado adecuadamente las dependencias temporales en los datos. La segunda gráfica, que muestra la serie temporal de los residuos, muestra que los residuos están distribuidos alrededor de cero con algunas fluctuaciones pero sin patrones evidentes de autocorrelación. Por su parte, el test de Box-Ljung muestra que los residuos son independientes, lo que indica que el modelo Prophet ha capturado adecuadamente las dependencias temporales en los datos. 

## Profundidad

```{r}
# Cargar el paquete
library(prophet)

# Asumiendo que los datos están en un data.frame llamado sismo_4_max_completo_filtrado
# Convertir las fechas y profundidades en un formato adecuado para Prophet
data_profundidad <- data.frame(
  ds = as.Date(sismo_4_max_completo_filtrado$FECHA), 
  y = sismo_4_max_completo_filtrado$MIN_PROFUNDIDAD
)

# Quitar los últimos 30 días de los datos
train_data_profundidad <- head(data_profundidad, -30)

# Ajustar el modelo Prophet con los datos de entrenamiento
modelo_profundidad_prophet <- prophet(train_data_profundidad)

# Hacer predicciones para los próximos 30 días
future <- make_future_dataframe(modelo_profundidad_prophet, periods = 30)
pronostico_profundidad_prophet <- predict(modelo_profundidad_prophet, future)

# Graficar las predicciones
plot(modelo_profundidad_prophet, pronostico_profundidad_prophet) +
  labs(title = "Pronóstico de Profundidad Mínima de Sismos", y = "Profundidad (km)", x = "Tiempo")

```
La línea azul central representa la predicción del modelo, mientras que las áreas sombreadas en azul claro indican los intervalos de confianza del 80% y 95%, respectivamente. Los puntos negros representan las observaciones reales de la profundidad de los sismos durante el período de tiempo mostrado. La mayoría de las observaciones se encuentran dentro de los intervalos de confianza, lo que sugiere que el modelo tiene un buen desempeño en capturar la variabilidad de la profundidad de los sismos. 


```{r}
# Calcular los residuos
residuales_profundidad_prophet <- train_data_profundidad$y - predict(modelo_profundidad_prophet, train_data_profundidad)$yhat

# Test de Shapiro-Wilk para normalidad de los residuos
shapiro_test <- shapiro.test(residuales_profundidad_prophet)
print(shapiro_test)

# Test de Box-Ljung para independencia de los residuos
box_ljung_test <- Box.test(residuales_profundidad_prophet, lag = 20, type = "Ljung-Box")
print(box_ljung_test)

# Graficar los residuos
residuals_df <- data.frame(time = train_data_profundidad$ds, residuals = residuales_profundidad_prophet)
ggplot(residuals_df, aes(x = time, y = residuals)) +
  geom_line() +
  labs(title = "Residuos del Modelo Prophet para Profundidad", x = "Tiempo", y = "Residuos")

# Graficar la función de autocorrelación de los residuos
acf(residuales_profundidad_prophet, main = "ACF de los Residuos del Modelo Prophet para Profundidad")

```
La gráfica muestra que, aunque la mayoría de los residuos se distribuyen alrededor de cero, hay algunos valores atípicos negativos que el modelo no ha capturado adecuadamente. La gráfica de autocorrelación (ACF) de los residuos, indica que no hay autocorrelación significativa, ya que todos los valores están dentro de las bandas de confianza.

Los resultados del test de Shapiro-Wilk (W = 0.34076, p-valor < 2.2e-16) sugieren que los residuos no siguen una distribución normal. Por otro lado, el test de Box-Ljung (X-squared = 3.2081, df = 20, p-valor = 1) indica que no hay autocorrelación significativa en los residuos. 


## Gráfica combinada Magnitud 

```{r}
# Cargar las librerías necesarias
library(prophet)
library(forecast)
library(ggplot2)

# Suponiendo que los datos están en el data.frame llamado sismo_4_max_completo
data_magnitud <- data.frame(
  ds = as.Date(sismo_4_max_completo$FECHA), 
  y = sismo_4_max_completo$MAX_MAGNITUD_ML
)

# Ajustar el modelo Prophet con estacionalidad diaria
modelo_magnitud_prophet <- prophet(data_magnitud, daily.seasonality = TRUE)

# Crear el dataframe futuro para predicciones de Prophet
future <- make_future_dataframe(modelo_magnitud_prophet, periods = 120)
pronostico_magnitud_prophet <- predict(modelo_magnitud_prophet, future)

# Ajustar el modelo ARIMA
modelo_arima <- auto.arima(data_magnitud$y)
pronostico_arima <- forecast::forecast(modelo_arima, h = 120)
# Crear un dataframe para los resultados de Prophet
resultados_prophet <- data.frame(
  ds = future$ds,
  yhat = pronostico_magnitud_prophet$yhat
)

# Crear un dataframe para los resultados de ARIMA
fechas_arima <- seq(max(data_magnitud$ds) + 1, by = "day", length.out = 120)
resultados_arima <- data.frame(
  ds = fechas_arima,
  yhat = pronostico_arima$mean
)

# Combinar los resultados con los datos originales
resultados_comb <- rbind(
  data.frame(ds = data_magnitud$ds, y = data_magnitud$y, modelo = "Datos"),
  data.frame(ds = resultados_prophet$ds, y = resultados_prophet$yhat, modelo = "Prophet"),
  data.frame(ds = resultados_arima$ds, y = resultados_arima$yhat, modelo = "ARIMA")
)
# Graficar los resultados
ggplot() +
  geom_line(data = resultados_comb[resultados_comb$modelo == "Datos", ], 
            aes(x = ds, y = y, color = modelo), size = 0.5) +
  geom_line(data = resultados_comb[resultados_comb$modelo == "Prophet", ], 
            aes(x = ds, y = y, color = modelo), size = 1) +
  geom_line(data = resultados_comb[resultados_comb$modelo == "ARIMA", ], 
            aes(x = ds, y = y, color = modelo), size = 1) +
  labs(title = "Pronóstico de Magnitud de Sismos: Prophet vs ARIMA",
       y = "Magnitud", x = "Fecha") +
  theme_minimal() +
  scale_color_manual(values = c("Datos" = "black", "Prophet" = "blue", "ARIMA" = "red"))

```
En general, ambos modelos parecen ser adecuados para capturar la tendencia general de la magnitud de los sismos.


## Gráfica combinada Pronóstico 

```{r}
library(prophet)
library(forecast)
library(ggplot2)

# Asumiendo que los datos están en un data.frame llamado sismo
# Convertir las fechas y profundidades en un formato adecuado para Prophet
data_profundidad <- data.frame(
  ds = as.Date(sismo_4_max_completo$FECHA), 
  y = sismo_4_max_completo$MIN_PROFUNDIDAD
)

# Ajustar el modelo Prophet
modelo_profundidad_prophet <- prophet(data_profundidad, daily.seasonality = TRUE)

# Hacer predicciones para los próximos 4 meses (120 días)
future <- make_future_dataframe(modelo_profundidad_prophet, periods = 120)
pronostico_profundidad_prophet <- predict(modelo_profundidad_prophet, future)

# Ajustar el modelo ARIMA
modelo_arima <- auto.arima(data_profundidad$y)
pronostico_arima <- forecast::forecast(modelo_arima, h = 120)
# Crear un dataframe para los resultados de Prophet
resultados_prophet <- data.frame(
  ds = future$ds,
  yhat = pronostico_profundidad_prophet$yhat
)

# Crear un dataframe para los resultados de ARIMA
fechas_arima <- seq(max(data_profundidad$ds) + 1, by = "day", length.out = 120)
resultados_arima <- data.frame(
  ds = fechas_arima,
  yhat = pronostico_arima$mean
)

# Combinar los resultados con los datos originales
resultados_comb <- rbind(
  data.frame(ds = data_profundidad$ds, y = data_profundidad$y, modelo = "Datos"),
  data.frame(ds = resultados_prophet$ds, y = resultados_prophet$yhat, modelo = "Prophet"),
  data.frame(ds = resultados_arima$ds, y = resultados_arima$yhat, modelo = "ARIMA")
)
# Graficar los resultados
ggplot() +
  geom_line(data = resultados_comb[resultados_comb$modelo == "Datos", ], 
            aes(x = ds, y = y, color = modelo), size = 0.5) +
  geom_line(data = resultados_comb[resultados_comb$modelo == "Prophet", ], 
            aes(x = ds, y = y, color = modelo), size = 1) +
  geom_line(data = resultados_comb[resultados_comb$modelo == "ARIMA", ], 
            aes(x = ds, y = y, color = modelo), size = 1) +
  labs(title = "Pronóstico de Profundidad de Sismos: Prophet vs ARIMA",
       y = "Pronostico", x = "Fecha") +
  theme_minimal() +
  scale_color_manual(values = c("Datos" = "black", "Prophet" = "blue", "ARIMA" = "red"))
```
En general, ambos modelos parecen ser adecuados para capturar la tendencia general de la magnitud de los sismos

# <span style="color:blue">**Modelo Elman**</span>

## Modelo Elman Profundidad

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_profundidad

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

elman_model <- elman(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(elman_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Profundidad",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Elman Profundidad con todo el historico', xlab = 'Fecha', ylab = 'Profundidad')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)
```
La primera gráfica compara las predicciones del modelo con los valores reales de profundidad de los sismos. Las líneas rojas representan los valores reales, mientras que las líneas turquesas representan las predicciones. Se observa que las predicciones siguen la tendencia general de los valores reales, aunque hay una considerable variabilidad en los datos reales que el modelo no logra capturar completamente. La segunda gráfica muestra las predicciones del modelo Elman para la profundidad de los sismos usando todo el histórico de datos. Las líneas azules representan los datos reales y las líneas rojas representan las predicciones del modelo. Se puede observar que el modelo Elman también sigue la tendencia general de los datos históricos, pero las predicciones son menos volátiles en comparación con los valores reales.


## Modelo Elman Magnitud

```{r}
#prueba de concepto Elman
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_magnitud

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

elman_model <- elman(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(elman_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Magnitud",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Elman Magnitud con todo el historico', xlab = 'Fecha', ylab = 'Magnitud')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)
```
La primera gráfica compara las predicciones de magnitud de los sismos (en turquesa) con los valores reales (en rojo) para el año 2017 y principios de 2018. Se observa que las predicciones siguen de cerca la línea central de los valores reales, pero no capturan completamente la variabilidad y los picos de los datos observados. La segunda gráfica muestra las predicciones del modelo Elman para la magnitud de los sismos utilizando todo el histórico de datos. Las líneas azules representan los datos reales y las líneas rojas las predicciones del modelo. El modelo Elman sigue la tendencia general de los datos históricos pero con menos variabilidad.


## Modelo Jordan Profundidad

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_profundidad

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

jordan_model <- jordan(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(jordan_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Profundidad",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Jordan Profundidad con todo el historico', xlab = 'Fecha', ylab = 'Profundidad')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)
```

Estas dos gráficas muestran predicciones de la profundidad de los sismos utilizando diferentes modelos. En la primera gráfica, se comparan los valores reales de la profundidad (línea roja) con las predicciones realizadas (línea azul claro) a lo largo del tiempo, indicando que las predicciones siguen de cerca los valores reales pero con cierta desviación. La segunda gráfica presenta las predicciones realizadas con el modelo Jordan (línea roja) contra los datos históricos (línea azul). Aquí, se observa que las predicciones del modelo Jordan tienden a estabilizarse en un rango más estrecho, lo cual puede indicar una mayor consistencia, pero también una posible subestimación de las fluctuaciones observadas en los datos reales.


## Modelo Jordan Magnitud

```{r}
library(ggplot2)
library(RSNNS)
library(dplyr)
data = data_magnitud

train_size <- floor(0.80 * nrow(data))

train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]


max_val <- max(data$y)
min_val <- min(data$y)

normalize <- function(x) {
  return ((x - min_val) / (max_val - min_val))
}

train_data$y <- normalize(train_data$y)
test_data$y <- normalize(test_data$y)

create_lagged_matrix <- function(data, lag) {
  inputs <- data %>%
    dplyr::mutate(lagged_y = dplyr::lag(y, lag)) %>%
    na.omit()
  
  inputs_matrix <- as.matrix(inputs$lagged_y)
  outputs_matrix <- as.matrix(inputs$y)
  
  return(list(inputs = inputs_matrix, outputs = outputs_matrix))
}

lag <- 2  

train_matrices <- create_lagged_matrix(train_data, lag)
test_matrices <- create_lagged_matrix(test_data, lag)

jordan_model <- jordan(train_matrices$inputs, train_matrices$outputs, size = c(5), maxit = 500, learnFuncParams = c(0.1), initFunc = "JE_Weights")

predictions <- predict(jordan_model, test_matrices$inputs)

# Desnormalizar las predicciones
denormalize <- function(x) {
  return (x * (max_val - min_val) + min_val)
}

predictions <- denormalize(predictions)

# Comparar las predicciones con los valores reales
results <- data.frame(
  Date = test_data$ds[(lag + 1):nrow(test_data)],
  Actual = denormalize(test_data$y[(lag + 1):nrow(test_data)]),
  Predicted = predictions
)

head(results,10)

ggplot(data = results, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted, color = "Predicted")) +
  labs(title = "Predicciones vs Valores Reales Magnitud",
       x = "Fecha",
       y = "Valor",
       color = "Leyenda") +
  theme_minimal()

test_data_new <- head(test_data, -2)


plot(data$ds, data$y, type = 'l', col = 'blue', main = 'Predicciones del Modelo Jordan Magnitud con todo el historico', xlab = 'Fecha', ylab = 'Magnitud')
lines(test_data_new$ds, predictions, col = 'red')
legend("bottomleft", legend = c("Real","Predicción Prueba"), col = c("blue", "red"), lty = 1)

```
Las dos gráficas muestran las predicciones de la magnitud de sismos utilizando dos modelos diferentes. La primera gráfica presenta las predicciones versus los valores reales, donde las predicciones están representadas por una línea (azul claro) y los valores reales por una (línea roja). Se observa que las predicciones del modelo siguen de cerca los valores reales, aunque con algunas desviaciones. La segunda gráfica muestra las predicciones del modelo Jordan comparadas con el histórico completo de los datos. En esta gráfica se observa que las predicciones del modelo Jordan tienden a mantenerse cerca de los valores reales, aunque con menos variabilidad que los datos históricos.


# <span style="color:blue">**Bibliografía**</span>

**Información sismica:**
https://www.infobae.com/colombia/2024/06/12/sismo-hoy-se-registro-un-temblor-en-el-municipio-de-los-santos-en-santander/
https://www.eltiempo.com/colombia/otras-ciudades/temblores-en-colombia-los-santos-el-municipio-donde-hay-mas-sismos-por-que-772495

**Base de datos:**
https://sish.sgc.gov.co/visor/
https://sish.sgc.gov.co/visor/sesionServlet?metodo=irAMunicipio&idDepartamento=68&idMunicipio=68418&cuadranteXMin=&cuadranteXMax=&cuadranteYMin=&cuadranteYMax=

**Descripción de las escalas**

HORA_UTC, MAGNITUD LOCAL, MAGNITUD DE MOMENTO, RMS, GAP
https://ds.iris.edu/latin_am/evlist.phtml?region=dom#:~:text=FECHA%20%2D%20HORA%20(UTC)%3A&text=La%20hora%20es%20expresada%20en,siete%20horas%20de%20Costa%20Rica.

http://www.ssn.unam.mx/jsp/reportesEspeciales/Magnitud-de-un-sismo.pdf

**Series de tiempo**
https://www.enae.es/curso/series-temporales?gad_source=1&gclid=CjwKCAjw7NmzBhBLEiwAxrHQ-ZlAegMbh59V8uZVHOTqUmvNTBkVxtmoUpLOH4wtw9Gwys1dWXmLSxoC9uUQAvD_BwE&_adin=02021864894









